{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score,f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sydwi\\AppData\\Local\\Temp\\ipykernel_25984\\3953763036.py:14: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  data = data.groupby('id').apply(lambda x: x.iloc[:-1]).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "#加载数据\n",
    "os.getcwd()\n",
    "data = pd.read_csv(os.getcwd()+'\\\\time_resampling\\\\featured_time_resamping_with_moodlevel.csv')\n",
    "data['time'] = pd.to_datetime(data['time'])\n",
    "\n",
    "###############\n",
    "#所有mood值向前移动一行\n",
    "data['mood'] = data.groupby('id')['mood'].shift(-1)\n",
    "\n",
    "# 按'id'和'time'排序，确保每个'id'分组的最后一行是时间最晚的\n",
    "data.sort_values(by=['id', 'time'], inplace=True)\n",
    "\n",
    "# 删除每个'id'分组的最后一行\n",
    "data = data.groupby('id').apply(lambda x: x.iloc[:-1]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "features = data.drop(columns=['mood','id','time',\"mood_level\"])\n",
    "target = data['mood_level']\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(features,target,test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sydwi\\miniconda3\\envs\\Env1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "324 fits failed out of a total of 972.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "152 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sydwi\\miniconda3\\envs\\Env1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\sydwi\\miniconda3\\envs\\Env1\\lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\sydwi\\miniconda3\\envs\\Env1\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\sydwi\\miniconda3\\envs\\Env1\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "172 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sydwi\\miniconda3\\envs\\Env1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\sydwi\\miniconda3\\envs\\Env1\\lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\sydwi\\miniconda3\\envs\\Env1\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\sydwi\\miniconda3\\envs\\Env1\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\sydwi\\miniconda3\\envs\\Env1\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [        nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.03006205 -0.00624395 -0.00624395\n",
      " -0.01814786 -0.000283   -0.00029072 -0.00029329 -0.018153    0.00566252\n",
      " -0.03005948 -0.00624395 -0.01220234 -0.03601529 -0.00029072 -0.01219977\n",
      " -0.0062491   0.00566252  0.00566252 -0.00029072 -0.00624653 -0.00029329\n",
      " -0.00029072 -0.00624653 -0.00029329  0.01162091 -0.00029072  0.01161833\n",
      " -0.03006205 -0.00624395 -0.00624395 -0.01814786 -0.000283   -0.00029072\n",
      " -0.00029329 -0.018153    0.00566252 -0.03005948 -0.00624395 -0.01220234\n",
      " -0.03601529 -0.00029072 -0.01219977 -0.0062491   0.00566252  0.00566252\n",
      " -0.00029072 -0.00624653 -0.00029329 -0.00029072 -0.00624653 -0.00029329\n",
      "  0.01162091 -0.00029072  0.01161833         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      " -0.01219462 -0.01815043 -0.00029329 -0.00623881 -0.01219719  0.0056651\n",
      " -0.018153   -0.00624138  0.0056651  -0.01219719 -0.01219719  0.0056651\n",
      " -0.03601529 -0.01219977 -0.0062491  -0.01219977 -0.00624395  0.00566252\n",
      "  0.00566252  0.0056651  -0.00029329  0.00566252  0.0056651  -0.00029329\n",
      "  0.01162091  0.01757415  0.01161833 -0.01219462 -0.01815043 -0.00029329\n",
      " -0.00623881 -0.01219719  0.0056651  -0.018153   -0.00624138  0.0056651\n",
      " -0.01219719 -0.01219719  0.0056651  -0.03601529 -0.01219977 -0.0062491\n",
      " -0.01219977 -0.00624395  0.00566252  0.00566252  0.0056651  -0.00029329\n",
      "  0.00566252  0.0056651  -0.00029329  0.01162091  0.01757415  0.01161833\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan -0.03006205 -0.00624395 -0.01219977\n",
      " -0.01814786 -0.000283   -0.00029072 -0.00029329 -0.018153    0.00566252\n",
      " -0.03005948 -0.00624395 -0.01220234 -0.03601529 -0.00029072 -0.01219977\n",
      " -0.0062491   0.00566252  0.00566252 -0.00029072 -0.00624653 -0.00029329\n",
      " -0.00029072 -0.00624653 -0.00029329  0.01162091 -0.00029072  0.01161833\n",
      " -0.03006205 -0.00624395 -0.01219977 -0.01814786 -0.000283   -0.00029072\n",
      " -0.00029329 -0.018153    0.00566252 -0.03005948 -0.00624395 -0.01220234\n",
      " -0.03601529 -0.00029072 -0.01219977 -0.0062491   0.00566252  0.00566252\n",
      " -0.00029072 -0.00624653 -0.00029329 -0.00029072 -0.00624653 -0.00029329\n",
      "  0.01162091 -0.00029072  0.01161833         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      " -0.03006205 -0.00624395 -0.00624395 -0.01814786 -0.000283   -0.00029072\n",
      " -0.00029329 -0.018153    0.00566252 -0.03005948 -0.00624395 -0.01220234\n",
      " -0.03601529 -0.00029072 -0.01219977 -0.0062491   0.00566252  0.00566252\n",
      " -0.00029072 -0.00624653 -0.00029329 -0.00029072 -0.00624653 -0.00029329\n",
      "  0.01162091 -0.00029072  0.01161833 -0.03006205 -0.00624395 -0.00624395\n",
      " -0.01814786 -0.000283   -0.00029072 -0.00029329 -0.018153    0.00566252\n",
      " -0.03005948 -0.00624395 -0.01220234 -0.03601529 -0.00029072 -0.01219977\n",
      " -0.0062491   0.00566252  0.00566252 -0.00029072 -0.00624653 -0.00029329\n",
      " -0.00029072 -0.00624653 -0.00029329  0.01162091 -0.00029072  0.01161833]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rt_classifier = RandomForestClassifier(random_state=1)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  # 树的数量\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],  # 考虑的最大特征数\n",
    "    'max_depth': [None, 10, 20, 30],  # 最大树深度\n",
    "    'min_samples_split': [2, 5, 10],  # 分割内部节点所需的最小样本数\n",
    "    'min_samples_leaf': [1, 2, 4]  # 叶节点所需的最小样本数\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=rt_classifier, param_grid=param_grid, cv=3, scoring='r2', n_jobs=-1, verbose=2)\n",
    "\n",
    "# 拟合网格搜索\n",
    "grid_search.fit(Xtrain, Ytrain)\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "best_rf = grid_search.best_estimator_\n",
    "val_predictions = best_rf.predict(Xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.820462398825193\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(Ytest, val_predictions, average='weighted')  #计算f1值\n",
    "print(f'F1 Score: {f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sydwi\\AppData\\Local\\Temp\\ipykernel_25984\\2302715881.py:14: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  data = data.groupby('id').apply(lambda x: x.iloc[:-1]).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#加载数据\n",
    "os.getcwd()\n",
    "data = pd.read_csv(os.getcwd()+'\\\\time_resampling\\\\featured_time_resamping_sparse_matrix_data.csv')\n",
    "data['time'] = pd.to_datetime(data['time'])\n",
    "\n",
    "###############\n",
    "#所有mood值向前移动一行\n",
    "data['mood'] = data.groupby('id')['mood'].shift(-1)\n",
    "\n",
    "# 按'id'和'time'排序，确保每个'id'分组的最后一行是时间最晚的\n",
    "data.sort_values(by=['id', 'time'], inplace=True)\n",
    "\n",
    "# 删除每个'id'分组的最后一行\n",
    "data = data.groupby('id').apply(lambda x: x.iloc[:-1]).reset_index(drop=True)\n",
    "################\n",
    "#data=data.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "\n",
    "# 提取年、月、日、星期几、小时等作为新特征\n",
    "# data['year'] = data['time'].dt.year\n",
    "# data['month'] = data['time'].dt.month\n",
    "# data['day'] = data['time'].dt.day\n",
    "# data['weekday'] = data['time'].dt.weekday\n",
    "# data['hour'] = data['time'].dt.hour\n",
    "\n",
    "# 使用正弦和余弦变换对月份和小时进行周期性编码\n",
    "# data['sin_month'] = np.sin(2 * np.pi * data['month'] / 12)\n",
    "# data['cos_month'] = np.cos(2 * np.pi * data['month'] / 12)\n",
    "# data['sin_hour'] = np.sin(2 * np.pi * data['hour'] / 24)\n",
    "# data['cos_hour'] = np.cos(2 * np.pi * data['hour'] / 24)\n",
    "\n",
    "\n",
    "features = data.drop(columns=['mood','id','time'])\n",
    "target = data['mood']\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(features,target,test_size=0.3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sydwi\\miniconda3\\envs\\Env1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "324 fits failed out of a total of 972.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "73 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sydwi\\miniconda3\\envs\\Env1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\sydwi\\miniconda3\\envs\\Env1\\lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\sydwi\\miniconda3\\envs\\Env1\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\sydwi\\miniconda3\\envs\\Env1\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "251 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\sydwi\\miniconda3\\envs\\Env1\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\sydwi\\miniconda3\\envs\\Env1\\lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\sydwi\\miniconda3\\envs\\Env1\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\sydwi\\miniconda3\\envs\\Env1\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\sydwi\\miniconda3\\envs\\Env1\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.15475055 0.16187541 0.16993176\n",
      " 0.16025058 0.1631877  0.16345397 0.15751115 0.15846129 0.16768158\n",
      " 0.17146305 0.16971807 0.17113491 0.16771637 0.17280744 0.17398772\n",
      " 0.16084321 0.16284697 0.16908667 0.17088755 0.17676335 0.17072967\n",
      " 0.17088755 0.17676335 0.17072967 0.15841528 0.16845619 0.17176463\n",
      " 0.14619657 0.15081746 0.1642892  0.15038043 0.15414494 0.16512669\n",
      " 0.1552992  0.15971429 0.16789769 0.15461836 0.15585883 0.16227783\n",
      " 0.1588989  0.16089613 0.16923119 0.16962137 0.16637877 0.16733346\n",
      " 0.1565977  0.16324066 0.16645649 0.1565977  0.16324066 0.16645649\n",
      " 0.15548825 0.15696194 0.16611414        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.13559385 0.15016037 0.16310847 0.16805037 0.16764913 0.16545386\n",
      " 0.15726723 0.16000099 0.16149123 0.16635912 0.16370106 0.16765013\n",
      " 0.14990614 0.15591485 0.16430253 0.15756307 0.16379107 0.16023422\n",
      " 0.16855743 0.17055155 0.16886414 0.16855743 0.17055155 0.16886414\n",
      " 0.16795827 0.16741219 0.17118027 0.14662388 0.15171276 0.16084704\n",
      " 0.15618328 0.15790953 0.16645243 0.1471787  0.1486427  0.15777661\n",
      " 0.15316408 0.15932947 0.1639327  0.15885918 0.15497734 0.16401649\n",
      " 0.15618171 0.15535607 0.15703403 0.15896702 0.15554696 0.16387938\n",
      " 0.15896702 0.15554696 0.16387938 0.15368264 0.15632464 0.16398934\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.14783325 0.15418349 0.16731291\n",
      " 0.1585658  0.164138   0.16852487 0.15872418 0.16093723 0.16740731\n",
      " 0.17072047 0.16737244 0.17046544 0.16833723 0.17763829 0.17683257\n",
      " 0.16025976 0.16174147 0.16815807 0.17043573 0.17622115 0.17085679\n",
      " 0.17043573 0.17622115 0.17085679 0.15822849 0.1688595  0.17220864\n",
      " 0.14186313 0.15127315 0.16534448 0.14638501 0.15624503 0.16537759\n",
      " 0.15481152 0.15888688 0.16920572 0.1577385  0.16054718 0.16523784\n",
      " 0.15914239 0.16020975 0.16883307 0.16572086 0.16460236 0.16652265\n",
      " 0.15689351 0.16326632 0.16670655 0.15689351 0.16326632 0.16670655\n",
      " 0.1556896  0.15689796 0.16628486        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.15475055 0.16175904 0.16986341 0.16093984 0.16352027 0.16361489\n",
      " 0.15751115 0.15846129 0.16768158 0.17146305 0.16971807 0.17113491\n",
      " 0.16771637 0.17280744 0.17398772 0.16084321 0.16284697 0.16908667\n",
      " 0.17088755 0.17676335 0.17072967 0.17088755 0.17676335 0.17072967\n",
      " 0.15841528 0.16845619 0.17176463 0.14619657 0.15028626 0.16403262\n",
      " 0.15038043 0.15414494 0.16512669 0.1552992  0.15971429 0.16789769\n",
      " 0.15461836 0.15585883 0.16227783 0.1588989  0.16089613 0.16923119\n",
      " 0.16962137 0.16637877 0.16733346 0.1565977  0.16324066 0.16645649\n",
      " 0.1565977  0.16324066 0.16645649 0.15548825 0.15696194 0.16611414]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# 实例化随机森林回归器\n",
    "rf_regressor = RandomForestRegressor(random_state=1)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  # 树的数量\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],  # 考虑的最大特征数\n",
    "    'max_depth': [None, 10, 20, 30],  # 最大树深度\n",
    "    'min_samples_split': [2, 5, 10],  # 分割内部节点所需的最小样本数\n",
    "    'min_samples_leaf': [1, 2, 4]  # 叶节点所需的最小样本数\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=rf_regressor, param_grid=param_grid, cv=3, scoring='r2', n_jobs=-1, verbose=2)\n",
    "\n",
    "# 拟合网格搜索\n",
    "grid_search.fit(Xtrain, Ytrain)\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "best_rf = grid_search.best_estimator_\n",
    "val_predictions = best_rf.predict(Xtest)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.03134041949116926\n",
      "Root Mean Squared Error (RMSE): 0.17703225551059687\n",
      "Mean Absolute Error (MAE): 0.11304387503801658\n",
      "R^2: 0.16745247019541631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sydwi\\miniconda3\\envs\\Env1\\lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "mse = mean_squared_error(Ytest, val_predictions)\n",
    "print(f'Mean Squared Error (MSE): {mse}')\n",
    "\n",
    "# 计算RMSE\n",
    "rmse = mean_squared_error(Ytest, val_predictions, squared=False)\n",
    "print(f'Root Mean Squared Error (RMSE): {rmse}')\n",
    "\n",
    "# 计算MAE\n",
    "mae = mean_absolute_error(Ytest, val_predictions)\n",
    "print(f'Mean Absolute Error (MAE): {mae}')\n",
    "\n",
    "# 计算R^2\n",
    "r2 = r2_score(Ytest, val_predictions)\n",
    "print(f'R^2: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
