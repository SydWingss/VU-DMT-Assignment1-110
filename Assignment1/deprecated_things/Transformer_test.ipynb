{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim import AdamW\n",
    "from rich.progress import Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('time_resampling/featured_time_resamping_sparse_matrix_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoodDataset(Dataset):\n",
    "    def __init__(self, features_1, features_2, labels):\n",
    "        self.features_1 = features_1\n",
    "        self.features_2 = features_2\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Convert features and labels to tensors\n",
    "        features_1 = torch.from_numpy(self.features_1[idx]).float()\n",
    "        features_2 = torch.from_numpy(self.features_2[idx]).float()\n",
    "        labels = torch.from_numpy(np.array(self.labels[idx])).float()\n",
    "        return features_1, features_2, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, num_features=21):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.transformer = nn.Transformer(d_model=num_features, nhead=1)\n",
    "        self.fc = nn.Linear(num_features, 1)\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        x = self.transformer(src, tgt)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by id\n",
    "grouped = df.groupby('id')\n",
    "\n",
    "# Data preparation\n",
    "features_1, features_2, labels = pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "for name, group in grouped:\n",
    "    feature_1 = group.drop(['id', 'time'], axis=1)\n",
    "    feature_2 = group.drop(['id', 'time'], axis=1)\n",
    "    label = group['mood']\n",
    "\n",
    "    feature_1 = feature_1.iloc[:-1].reset_index(drop=True)\n",
    "    feature_2 = feature_2.iloc[1:].reset_index(drop=True)\n",
    "    label = label.iloc[1:].reset_index(drop=True)\n",
    "    \n",
    "    # 添加feature到features，将label到labels\n",
    "    features_1 = pd.concat([features_1, feature_1])\n",
    "    features_2 = pd.concat([features_2, feature_2])\n",
    "    labels = pd.concat([labels, label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loong/miniconda3/envs/PyTorch/lib/python3.10/site-packages/torch/nn/modules/transformer.py:306: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "model = TransformerModel()\n",
    "optimizer = AdamW(model.parameters(), lr=0.00001)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test sets\n",
    "train_features_1, test_features_1, train_features_2, test_features_2, train_labels, test_labels = train_test_split(features_1.values, features_2.values, labels.values, test_size=0.2, shuffle=False)\n",
    "train_features_1, test_features_1, train_features_2, test_features_2, train_labels, test_labels = train_features_1.astype(np.float32), test_features_1.astype(np.float32), train_features_2.astype(np.float32), test_features_2.astype(np.float32), train_labels.astype(np.float32), test_labels.astype(np.float32)\n",
    "\n",
    "# Standardize features\n",
    "# scaler = StandardScaler()\n",
    "# train_features = scaler.fit_transform(train_features)\n",
    "# test_features = scaler.transform(test_features)\n",
    "\n",
    "# Create data loaders\n",
    "train_dataset = MoodDataset(train_features_1, train_features_2, train_labels)\n",
    "test_dataset = MoodDataset(test_features_1, test_features_2, test_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m src \u001b[38;5;241m=\u001b[39m inputs[:, :\u001b[38;5;241m21\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     10\u001b[0m tgt \u001b[38;5;241m=\u001b[39m inputs[:, \u001b[38;5;241m21\u001b[39m:]\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m---> 11\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43mlabels\u001b[49m\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# src = inputs[:-1].float()\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# tgt = inputs[1:].float()\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# labels = labels[1:].float()\u001b[39;00m\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m src \u001b[38;5;241m=\u001b[39m inputs[:, :\u001b[38;5;241m21\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     10\u001b[0m tgt \u001b[38;5;241m=\u001b[39m inputs[:, \u001b[38;5;241m21\u001b[39m:]\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m---> 11\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43mlabels\u001b[49m\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# src = inputs[:-1].float()\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# tgt = inputs[1:].float()\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# labels = labels[1:].float()\u001b[39;00m\n\u001b[1;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1395\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1344\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/PyTorch/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/PyTorch/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "for epoch in range(50):\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_count = 0\n",
    "\n",
    "    for i, (features_1, features_2, labels) in enumerate(train_loader):\n",
    "        src = features_1.float()\n",
    "        tgt = features_2.float()\n",
    "        labels = labels.float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(src, tgt).squeeze()\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate total loss and accuracy\n",
    "        total_loss += loss.item()\n",
    "        # total_correct += (outputs.argmax(dim=1) == tgt).sum().item()\n",
    "        total_count += tgt.size(0)\n",
    "    \n",
    "    # Print loss and accuracy for each epoch\n",
    "    print(f'Epoch {epoch+1}: Loss = {total_loss/total_count}, Accuracy = {total_correct/total_count}')\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), 'transformer.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "model.load_state_dict(torch.load('transformer.ckpt'))\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        # Remove last day's features as we don't have the next day's mood value\n",
    "        src = inputs[:-1].float()  # Add seq_len dimension\n",
    "        tgt = inputs[1:].float()  # Add seq_len dimension\n",
    "        labels = labels[1:].float()  # Add seq_len dimension\n",
    "\n",
    "        outputs = model(src, tgt).squeeze()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy: %d %%' % (100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
