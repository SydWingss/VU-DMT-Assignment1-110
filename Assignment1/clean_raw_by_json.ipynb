{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_schema = {\n",
    "    \"time\": {\n",
    "        \"description\": \"Timestamp in the format 'YYYY-MM-DD HH:MM:SS.FFF'\",\n",
    "        \"type\": \"string\",\n",
    "        \"pattern\": \"^\\\\d{4}-\\\\d{2}-\\\\d{2} \\\\d{2}:\\\\d{2}:\\\\d{2}\\\\.\\\\d{3}$\"\n",
    "    },\n",
    "    \"mood\": {\n",
    "        \"description\": \"The mood scored by the user on a scale of 1-10\",\n",
    "        \"type\": \"int\",\n",
    "        \"range\": (1, 10)\n",
    "    },\n",
    "    \"circumplex.arousal\": {\n",
    "        \"description\": \"The arousal scored by the user, on a scale between -2 to 2\",\n",
    "        \"type\": \"int\",\n",
    "        \"range\": (-2, 2)\n",
    "    },\n",
    "    \"circumplex.valence\": {\n",
    "        \"description\": \"The valence scored by the user, on a scale between -2 to 2\",\n",
    "        \"type\": \"int\",\n",
    "        \"range\": (-2, 2)\n",
    "    },\n",
    "    \"activity\": {\n",
    "        \"description\": \"Activity score of the user (number between 0 and 1)\",\n",
    "        \"type\": \"float\",\n",
    "        \"range\": (0, 1)\n",
    "    },\n",
    "    \"screen\": {\n",
    "        \"description\": \"Duration of screen activity (time)\",\n",
    "        \"type\": \"float\",\n",
    "        \"range\": None\n",
    "    },\n",
    "    \"call\": {\n",
    "        \"description\": \"Call made (indicated by a 1)\",\n",
    "        \"type\": \"int\",\n",
    "        \"range\": (0, 1)\n",
    "    },\n",
    "    \"sms\": {\n",
    "        \"description\": \"SMS sent (indicated by a 1)\",\n",
    "        \"type\": \"int\",\n",
    "        \"range\": (0, 1)\n",
    "    },\n",
    "    \"appCat.builtin\": {\n",
    "        \"description\": \"Duration of usage of builtin apps (time)\",\n",
    "        \"type\": \"float\",\n",
    "        \"range\": None\n",
    "    },\n",
    "    \"appCat.communication\": {\n",
    "        \"description\": \"Duration of usage of communication apps (time)\",\n",
    "        \"type\": \"float\",\n",
    "        \"range\": None\n",
    "    },\n",
    "    \"appCat.entertainment\": {\n",
    "        \"description\": \"Duration of usage of entertainment apps (time)\",\n",
    "        \"type\": \"float\",\n",
    "        \"range\": None\n",
    "    },\n",
    "    \"appCat.finance\": {\n",
    "        \"description\": \"Duration of usage of finance apps (time)\",\n",
    "        \"type\": \"float\",\n",
    "        \"range\": None\n",
    "    },\n",
    "    \"appCat.game\": {\n",
    "        \"description\": \"Duration of usage of game apps (time)\",\n",
    "        \"type\": \"float\",\n",
    "        \"range\": None\n",
    "    },\n",
    "    \"appCat.office\": {\n",
    "        \"description\": \"Duration of usage of office apps (time)\",\n",
    "        \"type\": \"float\",\n",
    "        \"range\": None\n",
    "    },\n",
    "    \"appCat.other\": {\n",
    "        \"description\": \"Duration of usage of other apps (time)\",\n",
    "        \"type\": \"float\",\n",
    "        \"range\": None\n",
    "    },\n",
    "    \"appCat.social\": {\n",
    "        \"description\": \"Duration of usage of social apps (time)\",\n",
    "        \"type\": \"float\",\n",
    "        \"range\": None\n",
    "    },\n",
    "    \"appCat.travel\": {\n",
    "        \"description\": \"Duration of usage of travel apps (time)\",\n",
    "        \"type\": \"float\",\n",
    "        \"range\": None\n",
    "    },\n",
    "    \"appCat.unknown\": {\n",
    "        \"description\": \"Duration of usage of unknown apps (time)\",\n",
    "        \"type\": \"float\",\n",
    "        \"range\": None\n",
    "    },\n",
    "    \"appCat.utilities\": {\n",
    "        \"description\": \"Duration of usage of utilities apps (time)\",\n",
    "        \"type\": \"float\",\n",
    "        \"range\": None\n",
    "    },\n",
    "    \"appCat.weather\": {\n",
    "        \"description\": \"Duration of usage of weather apps (time)\",\n",
    "        \"type\": \"float\",\n",
    "        \"range\": None\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import json\n",
    "# 创建一个新的json对象，其中只有\"time\"键\n",
    "new_data_schema = {\"time\": data_schema[\"time\"]}\n",
    "\n",
    "# 创建一个新的\"variable\"对象，其中包含除\"time\"之外的所有键值对\n",
    "new_data_schema[\"variable\"] = {key: value for key, value in data_schema.items() if key != \"time\"}\n",
    "\n",
    "# new_data_schema现在是修改后的json\n",
    "# 将new_data_schema保存为JSON\n",
    "with open(\"../Assignment1/threshold.json\", 'w') as f:\n",
    "    json.dump(new_data_schema, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-02-26 13:00:00.000</td>\n",
       "      <td>mood</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-02-26 15:00:00.000</td>\n",
       "      <td>mood</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-02-26 18:00:00.000</td>\n",
       "      <td>mood</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-02-26 21:00:00.000</td>\n",
       "      <td>mood</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-02-27 09:00:00.000</td>\n",
       "      <td>mood</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       id                     time variable  value\n",
       "1           1  AS14.01  2014-02-26 13:00:00.000     mood    6.0\n",
       "2           2  AS14.01  2014-02-26 15:00:00.000     mood    6.0\n",
       "3           3  AS14.01  2014-02-26 18:00:00.000     mood    6.0\n",
       "4           4  AS14.01  2014-02-26 21:00:00.000     mood    7.0\n",
       "5           5  AS14.01  2014-02-27 09:00:00.000     mood    6.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# 数据\n",
    "data=pd.read_csv('../Assignment1//dataset_mood_smartphone.csv')\n",
    "data.set_index(data.columns[0],inplace=True)\n",
    "data.reset_index(inplace=True)\n",
    "data.index += 1\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(data['value'].iloc[5708])\n",
    "print(data['value'].iloc[5708] is np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 记录不符合规定的行索引\n",
    "\n",
    "data_schema = pd.read_json(\"../Assignment1//threshold.json\")\n",
    "\n",
    "\n",
    "# 遍历每一行\n",
    "def clean_raw(data, data_schema):\n",
    "    invalid_rows = []\n",
    "    error_types = []\n",
    "    for index, row in data.iterrows():\n",
    "        # 检查时间是否符合规定\n",
    "        if not re.match(data_schema[\"time\"][\"pattern\"], row[\"time\"]):\n",
    "            invalid_rows.append(index + 1)\n",
    "            error_types.append(\"wrong_time\")\n",
    "            continue\n",
    "\n",
    "        # 检查变量是否符合规定\n",
    "        variable = row[\"variable\"]\n",
    "        value = row[\"value\"]\n",
    "        if variable in data_schema[\"variable\"]:\n",
    "            var_schema = data_schema[\"variable\"][variable]\n",
    "            if var_schema[\"range\"] is not None:\n",
    "                min_value, max_value = var_schema[\"range\"]\n",
    "                if not min_value <= value <= max_value:\n",
    "                    if pd.isnull(value):\n",
    "                        invalid_rows.append(index + 1)\n",
    "                        error_types.append(\"missing_value\")\n",
    "                    else:\n",
    "                        invalid_rows.append(index + 1)\n",
    "                        error_types.append(\"out_of_range\")\n",
    "        else:\n",
    "            invalid_rows.append(index + 1)\n",
    "            error_types.append(\"missing_variable\")\n",
    "\n",
    "    print(len(invalid_rows))\n",
    "    print(\"invalid row id:\", invalid_rows)\n",
    "    print(\"error types:\", error_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "data_str = \"\"\"\n",
    "\"\",\"id\",\"time\",\"variable\",\"value\"\n",
    "\"5639\",\"AS14.33\",\"2014-99-30 19:00:00.000\",\"mood\",8\n",
    "\"5640\",\"AS14.33\",\"2014-05-30 20:00:00.000\",\"NA\",6\n",
    "\"5641\",\"AS14.33\",\"2014-05-31 12:00:00.000\",\"mood\",110\n",
    "\"5642\",\"AS14.01\",\"2014-02-26 13:00:00.000\",\"circumplex.arousal\",NA\n",
    "\"5643\",\"AS14.01\",\"206 15:00:00.000\",\"circumplex.arousal\",-1\n",
    "\"5644\",\"AS14.01\",\"2014-02-26 18:00:00.000\",\"circumplex.arousal\",2000\n",
    "\"\"\"\n",
    "\n",
    "data = pd.read_csv(StringIO(data_str), quotechar='\"', skipinitialspace=True)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206\n",
      "invalid row id: [5710, 5732, 5774, 5798, 5837, 6326, 6380, 6435, 6669, 6794, 7038, 7257, 7263, 7321, 7349, 7451, 8194, 8203, 8351, 8358, 8363, 8384, 8405, 8462, 8468, 8644, 9333, 9391, 9395, 9400, 9444, 9479, 9504, 9520, 9647, 9920, 10190, 10242, 10249, 10263, 10284, 10293, 10294, 10330, 10335, 11257, 11301, 11353, 11380, 11381, 11383, 11416, 11417, 11420, 11480, 11481, 11489, 11498, 11969, 12023, 12068, 12078, 12312, 12325, 12437, 12681, 12775, 12900, 12925, 13038, 13048, 13052, 13053, 13062, 13180, 13184, 13188, 13204, 13750, 13800, 13821, 13824, 13827, 13844, 13846, 13854, 13861, 13888, 13898, 13929, 13946, 13960, 13962, 13966, 13975, 13978, 13993, 13994, 14001, 14004, 14009, 14020, 14023, 14027, 14029, 14036, 14039, 14045, 14048, 14055, 14056, 14057, 14064, 14071, 14072, 14086, 14090, 14098, 14102, 14105, 14106, 14107, 14111, 14114, 14287, 14313, 14314, 14316, 14325, 14330, 14331, 14337, 14340, 14936, 14940, 14973, 14976, 14983, 14985, 15026, 15031, 15033, 15034, 15038, 15040, 15041, 15042, 15043, 15047, 15077, 15087, 15122, 15123, 15127, 15147, 15163, 15165, 15166, 15168, 15169, 15563, 15832, 15833, 15844, 15846, 15861, 15879, 15885, 15887, 15892, 15906, 15911, 15914, 15916, 15922, 15927, 15928, 15936, 15937, 15945, 15947, 15972, 15973, 15978, 15979, 15980, 15984, 15985, 15987, 15991, 15992, 16781, 16804, 16810, 16816, 16853, 16854, 16860, 16863, 16883, 16900, 16904, 150042, 159974, 162156, 309807]\n",
      "error types: ['missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'out_of_range', 'out_of_range', 'out_of_range', 'out_of_range']\n"
     ]
    }
   ],
   "source": [
    "clean_raw(data, data_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN\n",
    "------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mood', 'circumplex.arousal', 'circumplex.valence', 'activity',\n",
       "       'screen', 'call', 'sms', 'appCat.builtin', 'appCat.communication',\n",
       "       'appCat.entertainment', 'appCat.finance', 'appCat.game',\n",
       "       'appCat.office', 'appCat.other', 'appCat.social', 'appCat.travel',\n",
       "       'appCat.unknown', 'appCat.utilities', 'appCat.weather'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert 'time' column to datetime format\n",
    "data['time'] = pd.to_datetime(data['time'])\n",
    "\n",
    "# Checking the unique variables in the dataset\n",
    "unique_variables = data['variable'].unique()\n",
    "\n",
    "unique_variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>value</th>\n",
       "      <th>value_imputed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [time, value, value_imputed]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Filtering the data for 'mood' variable\n",
    "mood_data = data[data['variable'] == 'mood'].copy()\n",
    "\n",
    "# Sorting the data by time to maintain time series order\n",
    "mood_data.sort_values(by='time', inplace=True)\n",
    "\n",
    "# We need to reset the index because KNNImputer relies on numerical indices to find nearest neighbors\n",
    "mood_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Selecting columns for imputation (using 'value' column only here as example)\n",
    "values_for_imputation = mood_data[['value']]\n",
    "\n",
    "# Setting up the KNN imputer, choosing 5 neighbors for simplicity\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# Performing the imputation\n",
    "mood_data['value_imputed'] = imputer.fit_transform(values_for_imputation)\n",
    "\n",
    "# Showing the original and imputed values to compare\n",
    "mood_data[mood_data['value'].isnull()][['time', 'value', 'value_imputed']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variable\n",
       "circumplex.valence      156\n",
       "circumplex.arousal       46\n",
       "activity                  0\n",
       "appCat.unknown            0\n",
       "screen                    0\n",
       "mood                      0\n",
       "call                      0\n",
       "appCat.weather            0\n",
       "appCat.utilities          0\n",
       "appCat.travel             0\n",
       "appCat.builtin            0\n",
       "appCat.social             0\n",
       "appCat.other              0\n",
       "appCat.office             0\n",
       "appCat.game               0\n",
       "appCat.finance            0\n",
       "appCat.entertainment      0\n",
       "appCat.communication      0\n",
       "sms                       0\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting missing values by variable type\n",
    "missing_by_variable = data.groupby('variable')['value'].apply(lambda x: x.isnull().sum())\n",
    "missing_by_variable_sorted = missing_by_variable.sort_values(ascending=False)\n",
    "\n",
    "missing_by_variable_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>value</th>\n",
       "      <th>value_imputed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>2014-04-01 15:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.098624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>2014-04-01 19:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.098624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>2014-04-02 18:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.098624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>2014-04-06 12:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.098624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1825</th>\n",
       "      <td>2014-04-06 21:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.098624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    time  value  value_imputed\n",
       "1247 2014-04-01 15:00:00    NaN      -0.098624\n",
       "1268 2014-04-01 19:00:00    NaN      -0.098624\n",
       "1361 2014-04-02 18:00:00    NaN      -0.098624\n",
       "1744 2014-04-06 12:00:00    NaN      -0.098624\n",
       "1825 2014-04-06 21:00:00    NaN      -0.098624"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering the data for 'circumplex.valence' variable\n",
    "valence_data = data[data['variable'] == 'circumplex.arousal'].copy()\n",
    "\n",
    "# Sorting the data by time to maintain time series order\n",
    "valence_data.sort_values(by='time', inplace=True)\n",
    "\n",
    "# Reset the index because KNNImputer relies on numerical indices to find nearest neighbors\n",
    "valence_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Selecting columns for imputation (using 'value' column only here as example)\n",
    "valence_values_for_imputation = valence_data[['value']]\n",
    "\n",
    "# Setting up the KNN imputer, choosing 5 neighbors for simplicity\n",
    "valence_imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# Performing the imputation\n",
    "valence_data['value_imputed'] = valence_imputer.fit_transform(valence_values_for_imputation)\n",
    "\n",
    "# Showing the original and imputed values to compare\n",
    "valence_data[valence_data['value'].isnull()][['time', 'value', 'value_imputed']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_44514/1818056308.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  missing_data_analysis = data.groupby('variable').apply(lambda x: x['value'].isnull().sum())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "variable\n",
       "activity                  0\n",
       "appCat.builtin            0\n",
       "appCat.communication      0\n",
       "appCat.entertainment      0\n",
       "appCat.finance            0\n",
       "appCat.game               0\n",
       "appCat.office             0\n",
       "appCat.other              0\n",
       "appCat.social             0\n",
       "appCat.travel             0\n",
       "appCat.unknown            0\n",
       "appCat.utilities          0\n",
       "appCat.weather            0\n",
       "call                      0\n",
       "circumplex.arousal       46\n",
       "circumplex.valence      156\n",
       "mood                      0\n",
       "screen                    0\n",
       "sms                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Remove the unnecessary 'Unnamed: 0' column\n",
    "data = data.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Step 2: Convert 'time' column to datetime format\n",
    "data['time'] = pd.to_datetime(data['time'])\n",
    "\n",
    "# Step 3: Analyze missing data by 'variable' type\n",
    "missing_data_analysis = data.groupby('variable').apply(lambda x: x['value'].isnull().sum())\n",
    "\n",
    "# Display the missing data analysis by variable\n",
    "missing_data_analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.67, -0.56, -0.43, -0.62, -0.65, -0.55, -0.17, -0.4 , -0.98,\n",
       "       -0.3 , -0.98, -0.01,  0.  ,  0.01,  0.  ,  0.  ,  1.  ,  1.  ,\n",
       "        0.67,  0.82,  0.59,  1.22,  0.82,  0.82,  0.82,  1.  ,  0.  ,\n",
       "        0.01,  0.14,  0.16,  0.14,  0.14,  0.14,  0.14, -0.01,  0.06,\n",
       "       -0.28,  0.98, -0.29, -0.14, -0.28,  0.48, -0.3 , -0.28, -0.28,\n",
       "       -0.36])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Label encoding for categorical data\n",
    "label_encoder_id = LabelEncoder()\n",
    "data['id_encoded'] = label_encoder_id.fit_transform(data['id'])\n",
    "\n",
    "label_encoder_variable = LabelEncoder()\n",
    "data['variable_encoded'] = label_encoder_variable.fit_transform(data['variable'])\n",
    "\n",
    "# Function to prepare data for filling missing values with RandomForest\n",
    "def prepare_data_for_rf(variable_name):\n",
    "    # Selecting rows related to the variable\n",
    "    variable_data = data[data['variable'] == variable_name]\n",
    "\n",
    "    # Separating into data with and without missing values\n",
    "    known_data = variable_data[variable_data['value'].notna()]\n",
    "    unknown_data = variable_data[variable_data['value'].isna()]\n",
    "\n",
    "    # Selecting features and target\n",
    "    features = known_data[['id_encoded', 'variable_encoded', 'time']]\n",
    "    target = known_data['value']\n",
    "\n",
    "    # One-hot encoding for time features\n",
    "    features = pd.get_dummies(features, columns=['time'])\n",
    "\n",
    "    # Splitting the data for training\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, unknown_data, features.columns\n",
    "\n",
    "# Prepare data for 'circumplex.arousal'\n",
    "X_train_arousal, X_test_arousal, y_train_arousal, y_test_arousal, unknown_data_arousal, feature_cols_arousal = prepare_data_for_rf('circumplex.arousal')\n",
    "\n",
    "# Initialize and train the RandomForest model\n",
    "model_arousal = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model_arousal.fit(X_train_arousal, y_train_arousal)\n",
    "\n",
    "# Predict the missing values\n",
    "unknown_data_arousal_features = pd.get_dummies(unknown_data_arousal[['id_encoded', 'variable_encoded', 'time']], columns=['time'])\n",
    "unknown_data_arousal_features = unknown_data_arousal_features.reindex(columns=feature_cols_arousal, fill_value=0)\n",
    "predicted_values_arousal = model_arousal.predict(unknown_data_arousal_features)\n",
    "\n",
    "# Display predictions\n",
    "predicted_values_arousal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.  ,  0.8 ,  1.  ,  0.99,  0.9 ,  1.  ,  1.  ,  0.82,  1.  ,\n",
       "        1.  ,  1.01,  1.  ,  1.  ,  1.  ,  1.  ,  0.97,  1.  ,  1.  ,\n",
       "        1.  ,  0.82,  1.  ,  0.95,  0.92,  1.  ,  1.  ,  1.  ,  0.52,\n",
       "        1.  ,  1.  ,  0.84,  1.  ,  1.  ,  1.  ,  1.16,  1.  ,  1.  ,\n",
       "        0.98,  1.  ,  1.  ,  1.  ,  0.92,  1.  ,  0.41,  0.79,  1.  ,\n",
       "        1.  ,  0.76,  1.  ,  1.  ,  1.  ,  1.  ,  0.45,  0.92,  1.  ,\n",
       "        1.  ,  1.  ,  1.  ,  1.  ,  0.99,  1.  ,  0.94, -0.31,  0.99,\n",
       "        1.  ,  0.8 ,  0.84,  1.  ,  1.  ,  1.  ,  0.5 , -0.12,  1.  ,\n",
       "        0.96,  1.  ,  0.41,  0.37,  0.28,  1.  ,  1.  ,  1.  ,  0.47,\n",
       "        0.96,  1.  ,  1.  ,  0.87,  1.  ,  1.  ,  1.  ,  1.  ,  1.  ,\n",
       "        0.99,  0.98,  0.9 ,  1.  ,  1.  ,  1.  ,  1.  ,  1.  ,  1.  ,\n",
       "        1.  ,  1.  ,  1.  ,  0.98,  1.  ,  1.  ,  1.  ,  1.  ,  1.  ,\n",
       "        1.  ,  1.  ,  1.  ,  1.  ,  1.  ,  1.  ,  0.46,  1.  ,  1.  ,\n",
       "        1.  ,  1.  ,  1.  ,  1.  ,  1.  ,  1.  ,  0.86,  1.53,  1.  ,\n",
       "        0.94,  0.59,  1.  ,  0.77,  1.  ,  0.46,  1.  ,  0.51,  0.44,\n",
       "        1.  ,  0.45,  1.  ,  1.  ,  1.  ,  1.  ,  1.  ,  1.  ,  1.  ,\n",
       "        1.  ,  0.97,  0.99,  0.97,  0.27,  0.97,  0.97,  0.97,  0.97,\n",
       "        0.97,  0.97,  0.97])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data for 'circumplex.valence'\n",
    "X_train_valence, X_test_valence, y_train_valence, y_test_valence, unknown_data_valence, feature_cols_valence = prepare_data_for_rf('circumplex.valence')\n",
    "\n",
    "# Initialize and train the RandomForest model for 'circumplex.valence'\n",
    "model_valence = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model_valence.fit(X_train_valence, y_train_valence)\n",
    "\n",
    "# Predict the missing values for 'circumplex.valence'\n",
    "unknown_data_valence_features = pd.get_dummies(unknown_data_valence[['id_encoded', 'variable_encoded', 'time']], columns=['time'])\n",
    "unknown_data_valence_features = unknown_data_valence_features.reindex(columns=feature_cols_valence, fill_value=0)\n",
    "predicted_values_valence = model_valence.predict(unknown_data_valence_features)\n",
    "\n",
    "# Display predictions for 'circumplex.valence'\n",
    "predicted_values_valence\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
