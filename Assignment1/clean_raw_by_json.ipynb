{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-02-26 13:00:00.000</td>\n",
       "      <td>mood</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-02-26 15:00:00.000</td>\n",
       "      <td>mood</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-02-26 18:00:00.000</td>\n",
       "      <td>mood</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-02-26 21:00:00.000</td>\n",
       "      <td>mood</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>AS14.01</td>\n",
       "      <td>2014-02-27 09:00:00.000</td>\n",
       "      <td>mood</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       id                     time variable  value\n",
       "1           1  AS14.01  2014-02-26 13:00:00.000     mood    6.0\n",
       "2           2  AS14.01  2014-02-26 15:00:00.000     mood    6.0\n",
       "3           3  AS14.01  2014-02-26 18:00:00.000     mood    6.0\n",
       "4           4  AS14.01  2014-02-26 21:00:00.000     mood    7.0\n",
       "5           5  AS14.01  2014-02-27 09:00:00.000     mood    6.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# 数据\n",
    "data=pd.read_csv('../Assignment1//dataset_mood_smartphone.csv')\n",
    "data.set_index(data.columns[0],inplace=True)\n",
    "data.reset_index(inplace=True)\n",
    "data.index += 1\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(data['value'].iloc[5708])\n",
    "print(data['value'].iloc[5708] is np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 记录不符合规定的行索引\n",
    "\n",
    "data_schema = pd.read_json(\"../Assignment1//threshold.json\")\n",
    "\n",
    "\n",
    "# 遍历每一行\n",
    "def clean_raw(data, data_schema):\n",
    "    invalid_rows = []\n",
    "    error_types = []\n",
    "    for index, row in data.iterrows():\n",
    "        # 检查时间是否符合规定\n",
    "        if not re.match(data_schema[\"time\"][\"pattern\"], row[\"time\"]):\n",
    "            invalid_rows.append(index + 1)\n",
    "            error_types.append(\"wrong_time\")\n",
    "            continue\n",
    "\n",
    "        # 检查变量是否符合规定\n",
    "        variable = row[\"variable\"]\n",
    "        value = row[\"value\"]\n",
    "        if variable in data_schema[\"variable\"]:\n",
    "            var_schema = data_schema[\"variable\"][variable]\n",
    "            if var_schema[\"range\"] is not None:\n",
    "                min_value, max_value = var_schema[\"range\"]\n",
    "                if not min_value <= value <= max_value:\n",
    "                    if pd.isnull(value):\n",
    "                        invalid_rows.append(index + 1)\n",
    "                        error_types.append(\"missing_value\")\n",
    "                    else:\n",
    "                        invalid_rows.append(index + 1)\n",
    "                        error_types.append(\"out_of_range\")\n",
    "        else:\n",
    "            invalid_rows.append(index + 1)\n",
    "            error_types.append(\"missing_variable\")\n",
    "\n",
    "    print(len(invalid_rows))\n",
    "    print(\"invalid row id:\", invalid_rows)\n",
    "    print(\"error types:\", error_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206\n",
      "invalid row id: [5710, 5732, 5774, 5798, 5837, 6326, 6380, 6435, 6669, 6794, 7038, 7257, 7263, 7321, 7349, 7451, 8194, 8203, 8351, 8358, 8363, 8384, 8405, 8462, 8468, 8644, 9333, 9391, 9395, 9400, 9444, 9479, 9504, 9520, 9647, 9920, 10190, 10242, 10249, 10263, 10284, 10293, 10294, 10330, 10335, 11257, 11301, 11353, 11380, 11381, 11383, 11416, 11417, 11420, 11480, 11481, 11489, 11498, 11969, 12023, 12068, 12078, 12312, 12325, 12437, 12681, 12775, 12900, 12925, 13038, 13048, 13052, 13053, 13062, 13180, 13184, 13188, 13204, 13750, 13800, 13821, 13824, 13827, 13844, 13846, 13854, 13861, 13888, 13898, 13929, 13946, 13960, 13962, 13966, 13975, 13978, 13993, 13994, 14001, 14004, 14009, 14020, 14023, 14027, 14029, 14036, 14039, 14045, 14048, 14055, 14056, 14057, 14064, 14071, 14072, 14086, 14090, 14098, 14102, 14105, 14106, 14107, 14111, 14114, 14287, 14313, 14314, 14316, 14325, 14330, 14331, 14337, 14340, 14936, 14940, 14973, 14976, 14983, 14985, 15026, 15031, 15033, 15034, 15038, 15040, 15041, 15042, 15043, 15047, 15077, 15087, 15122, 15123, 15127, 15147, 15163, 15165, 15166, 15168, 15169, 15563, 15832, 15833, 15844, 15846, 15861, 15879, 15885, 15887, 15892, 15906, 15911, 15914, 15916, 15922, 15927, 15928, 15936, 15937, 15945, 15947, 15972, 15973, 15978, 15979, 15980, 15984, 15985, 15987, 15991, 15992, 16781, 16804, 16810, 16816, 16853, 16854, 16860, 16863, 16883, 16900, 16904, 150042, 159974, 162156, 309807]\n",
      "error types: ['missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'missing_value', 'out_of_range', 'out_of_range', 'out_of_range', 'out_of_range']\n"
     ]
    }
   ],
   "source": [
    "clean_raw(data, data_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN\n",
    "------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert 'time' column to datetime format\n",
    "data['time'] = pd.to_datetime(data['time'])\n",
    "\n",
    "# Checking the unique variables in the dataset\n",
    "unique_variables = data['variable'].unique()\n",
    "\n",
    "unique_variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Filtering the data for 'mood' variable\n",
    "mood_data = data[data['variable'] == 'mood'].copy()\n",
    "\n",
    "# Sorting the data by time to maintain time series order\n",
    "mood_data.sort_values(by='time', inplace=True)\n",
    "\n",
    "# We need to reset the index because KNNImputer relies on numerical indices to find nearest neighbors\n",
    "mood_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Selecting columns for imputation (using 'value' column only here as example)\n",
    "values_for_imputation = mood_data[['value']]\n",
    "\n",
    "# Setting up the KNN imputer, choosing 5 neighbors for simplicity\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# Performing the imputation\n",
    "mood_data['value_imputed'] = imputer.fit_transform(values_for_imputation)\n",
    "\n",
    "# Showing the original and imputed values to compare\n",
    "mood_data[mood_data['value'].isnull()][['time', 'value', 'value_imputed']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting missing values by variable type\n",
    "missing_by_variable = data.groupby('variable')['value'].apply(lambda x: x.isnull().sum())\n",
    "missing_by_variable_sorted = missing_by_variable.sort_values(ascending=False)\n",
    "\n",
    "missing_by_variable_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering the data for 'circumplex.valence' variable\n",
    "valence_data = data[data['variable'] == 'circumplex.arousal'].copy()\n",
    "\n",
    "# Sorting the data by time to maintain time series order\n",
    "valence_data.sort_values(by='time', inplace=True)\n",
    "\n",
    "# Reset the index because KNNImputer relies on numerical indices to find nearest neighbors\n",
    "valence_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Selecting columns for imputation (using 'value' column only here as example)\n",
    "valence_values_for_imputation = valence_data[['value']]\n",
    "\n",
    "# Setting up the KNN imputer, choosing 5 neighbors for simplicity\n",
    "valence_imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# Performing the imputation\n",
    "valence_data['value_imputed'] = valence_imputer.fit_transform(valence_values_for_imputation)\n",
    "\n",
    "# Showing the original and imputed values to compare\n",
    "valence_data[valence_data['value'].isnull()][['time', 'value', 'value_imputed']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43512/1818056308.py:8: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  missing_data_analysis = data.groupby('variable').apply(lambda x: x['value'].isnull().sum())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "variable\n",
       "activity                  0\n",
       "appCat.builtin            0\n",
       "appCat.communication      0\n",
       "appCat.entertainment      0\n",
       "appCat.finance            0\n",
       "appCat.game               0\n",
       "appCat.office             0\n",
       "appCat.other              0\n",
       "appCat.social             0\n",
       "appCat.travel             0\n",
       "appCat.unknown            0\n",
       "appCat.utilities          0\n",
       "appCat.weather            0\n",
       "call                      0\n",
       "circumplex.arousal       46\n",
       "circumplex.valence      156\n",
       "mood                      0\n",
       "screen                    0\n",
       "sms                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Remove the unnecessary 'Unnamed: 0' column\n",
    "data = data.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Step 2: Convert 'time' column to datetime format\n",
    "data['time'] = pd.to_datetime(data['time'])\n",
    "\n",
    "# Step 3: Analyze missing data by 'variable' type\n",
    "missing_data_analysis = data.groupby('variable').apply(lambda x: x['value'].isnull().sum())\n",
    "\n",
    "# Display the missing data analysis by variable\n",
    "missing_data_analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.67 -0.56 -0.43 -0.62 -0.65 -0.55 -0.17 -0.4  -0.98 -0.3  -0.98 -0.01\n",
      "  0.    0.01  0.    0.    1.    1.    0.67  0.82  0.59  1.22  0.82  0.82\n",
      "  0.82  1.    0.    0.01  0.14  0.16  0.14  0.14  0.14  0.14 -0.01  0.06\n",
      " -0.28  0.98 -0.29 -0.14 -0.28  0.48 -0.3  -0.28 -0.28 -0.36]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Label encoding for categorical data\n",
    "label_encoder_id = LabelEncoder()\n",
    "data['id_encoded'] = label_encoder_id.fit_transform(data['id'])\n",
    "\n",
    "label_encoder_variable = LabelEncoder()\n",
    "data['variable_encoded'] = label_encoder_variable.fit_transform(data['variable'])\n",
    "\n",
    "# Function to prepare data for filling missing values with RandomForest\n",
    "def prepare_data_for_rf(variable_name):\n",
    "    # Selecting rows related to the variable\n",
    "    variable_data = data[data['variable'] == variable_name]\n",
    "\n",
    "    # Separating into data with and without missing values\n",
    "    known_data = variable_data[variable_data['value'].notna()]\n",
    "    unknown_data = variable_data[variable_data['value'].isna()]\n",
    "\n",
    "    # Selecting features and target\n",
    "    features = known_data[['id_encoded', 'variable_encoded', 'time']]\n",
    "    target = known_data['value']\n",
    "\n",
    "    # One-hot encoding for time features\n",
    "    features = pd.get_dummies(features, columns=['time'])\n",
    "\n",
    "    # Splitting the data for training\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, unknown_data, features.columns\n",
    "\n",
    "# Prepare data for 'circumplex.arousal'\n",
    "X_train_arousal, X_test_arousal, y_train_arousal, y_test_arousal, unknown_data_arousal, feature_cols_arousal = prepare_data_for_rf('circumplex.arousal')\n",
    "\n",
    "# Initialize and train the RandomForest model\n",
    "model_arousal = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model_arousal.fit(X_train_arousal, y_train_arousal)\n",
    "\n",
    "# Predict the missing values\n",
    "unknown_data_arousal_features = pd.get_dummies(unknown_data_arousal[['id_encoded', 'variable_encoded', 'time']], columns=['time'])\n",
    "unknown_data_arousal_features = unknown_data_arousal_features.reindex(columns=feature_cols_arousal, fill_value=0)\n",
    "predicted_values_arousal = model_arousal.predict(unknown_data_arousal_features)\n",
    "\n",
    "# Display predictions\n",
    "print(predicted_values_arousal)\n",
    "\n",
    "# Assuming 'predicted_values_arousal' is a numpy array or a Pandas Series\n",
    "unknown_data_arousal['value'] = predicted_values_arousal\n",
    "\n",
    "# Fill the predicted values back to the original DataFrame\n",
    "data.loc[unknown_data_arousal.index, 'value'] = unknown_data_arousal['value']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.    0.8   1.    0.99  0.9   1.    1.    0.82  1.    1.    1.01  1.\n",
      "  1.    1.    1.    0.97  1.    1.    1.    0.82  1.    0.95  0.92  1.\n",
      "  1.    1.    0.52  1.    1.    0.84  1.    1.    1.    1.16  1.    1.\n",
      "  0.98  1.    1.    1.    0.92  1.    0.41  0.79  1.    1.    0.76  1.\n",
      "  1.    1.    1.    0.45  0.92  1.    1.    1.    1.    1.    0.99  1.\n",
      "  0.94 -0.31  0.99  1.    0.8   0.84  1.    1.    1.    0.5  -0.12  1.\n",
      "  0.96  1.    0.41  0.37  0.28  1.    1.    1.    0.47  0.96  1.    1.\n",
      "  0.87  1.    1.    1.    1.    1.    0.99  0.98  0.9   1.    1.    1.\n",
      "  1.    1.    1.    1.    1.    1.    0.98  1.    1.    1.    1.    1.\n",
      "  1.    1.    1.    1.    1.    1.    0.46  1.    1.    1.    1.    1.\n",
      "  1.    1.    1.    0.86  1.53  1.    0.94  0.59  1.    0.77  1.    0.46\n",
      "  1.    0.51  0.44  1.    0.45  1.    1.    1.    1.    1.    1.    1.\n",
      "  1.    0.97  0.99  0.97  0.27  0.97  0.97  0.97  0.97  0.97  0.97  0.97]\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for 'circumplex.valence'\n",
    "(\n",
    "    X_train_valence,\n",
    "    X_test_valence,\n",
    "    y_train_valence,\n",
    "    y_test_valence,\n",
    "    unknown_data_builtin,\n",
    "    feature_cols_builtin,\n",
    ") = prepare_data_for_rf(\"circumplex.valence\")\n",
    "\n",
    "# Initialize and train the RandomForest model for 'circumplex.valence'\n",
    "model_valence = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model_valence.fit(X_train_valence, y_train_valence)\n",
    "\n",
    "# Predict the missing values for 'circumplex.valence'\n",
    "unknown_data_valence_features = pd.get_dummies(\n",
    "    unknown_data_builtin[[\"id_encoded\", \"variable_encoded\", \"time\"]], columns=[\"time\"]\n",
    ")\n",
    "unknown_data_valence_features = unknown_data_valence_features.reindex(\n",
    "    columns=feature_cols_builtin, fill_value=0\n",
    ")\n",
    "predicted_values_valence = model_valence.predict(unknown_data_valence_features)\n",
    "\n",
    "# Display predictions for 'circumplex.valence'\n",
    "print(predicted_values_valence)\n",
    "unknown_data_builtin[\"value\"] = predicted_values_valence\n",
    "data.loc[unknown_data_builtin.index, \"value\"] = unknown_data_builtin[\"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id                time variable  value  id_encoded  variable_encoded\n",
      "1  AS14.01 2014-02-26 13:00:00     mood    6.0           0                16\n",
      "2  AS14.01 2014-02-26 15:00:00     mood    6.0           0                16\n",
      "3  AS14.01 2014-02-26 18:00:00     mood    6.0           0                16\n",
      "4  AS14.01 2014-02-26 21:00:00     mood    7.0           0                16\n",
      "5  AS14.01 2014-02-27 09:00:00     mood    6.0           0                16\n"
     ]
    }
   ],
   "source": [
    "print(data.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150041      -44.689\n",
      "159973   -82798.871\n",
      "162155       -1.218\n",
      "309806       -0.011\n",
      "Name: value, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# List of invalid row ids\n",
    "invalid_row_ids = [150042, 159974, 162156, 309807]\n",
    "\n",
    "# Subtract 1 from all ids\n",
    "invalid_row_ids = [id-1 for id in invalid_row_ids]\n",
    "\n",
    "# Select these rows\n",
    "invalid_rows = data[data.index.isin(invalid_row_ids)]\n",
    "\n",
    "# Print the 'value' column of these rows\n",
    "print(invalid_rows['value'])\n",
    "data.loc[invalid_row_ids, 'value'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=['value'])\n",
    "# Convert 'time' column to string\n",
    "data['time'] = data['time'].dt.strftime('%Y-%m-%d %H:%M:%S.%f')\n",
    "# Remove the last 3 digits (microseconds to milliseconds)\n",
    "data['time'] = data['time'].str[:-3]\n",
    "data = data.drop(['id_encoded', 'variable_encoded'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "invalid row id: []\n",
      "error types: []\n"
     ]
    }
   ],
   "source": [
    "clean_raw(data,data_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('cleaned_dataset_mood_smartphone.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
